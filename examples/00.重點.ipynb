{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model providers\n",
    "\n",
    "Jupyter AI supports a wide range of model providers and models. To use Jupyter AI with a particular provider, you must install its Python packages and set its API key (or other credentials) in your environment or in the chat interface.\n",
    "\n",
    "Jupyter AI supports the following model providers:\n",
    "\n",
    "| Provider            | Provider ID          | Environment variable(s)    | Python package(s)               |\n",
    "|---------------------|----------------------|----------------------------|---------------------------------|\n",
    "| AI21                | `ai21`               | `AI21_API_KEY`             | `ai21`                          |\n",
    "| Anthropic           | `anthropic`          | `ANTHROPIC_API_KEY`        | `anthropic`                     |\n",
    "| Anthropic (chat)    | `anthropic-chat`     | `ANTHROPIC_API_KEY`        | `anthropic`                     |\n",
    "| Bedrock             | `bedrock`            | N/A                        | `boto3`                         |\n",
    "| Bedrock (chat)      | `bedrock-chat`       | N/A                        | `boto3`                         |\n",
    "| Cohere              | `cohere`             | `COHERE_API_KEY`           | `cohere`                        |\n",
    "| ERNIE-Bot           | `qianfan`            | `QIANFAN_AK`, `QIANFAN_SK` | `qianfan`                       |\n",
    "| Gemini              | `gemini`             | `GOOGLE_API_KEY`           | `langchain-google-genai`        |\n",
    "| GPT4All             | `gpt4all`            | N/A                        | `gpt4all`                       |\n",
    "| Hugging Face Hub    | `huggingface_hub`    | `HUGGINGFACEHUB_API_TOKEN` | `huggingface_hub`, `ipywidgets`, `pillow` |\n",
    "| NVIDIA              | `nvidia-chat`        | `NVIDIA_API_KEY`           | `langchain_nvidia_ai_endpoints` |\n",
    "| OpenAI              | `openai`             | `OPENAI_API_KEY`           | `openai`                        |\n",
    "| OpenAI (chat)       | `openai-chat`        | `OPENAI_API_KEY`           | `openai`                        |\n",
    "| SageMaker           | `sagemaker-endpoint` | N/A                        | `boto3`                         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 選擇提供程式和模型 Choosing a provider and model\n",
    "\n",
    "%%ai 單元格魔術允許您使用給定的提示調用您選擇的語言模型。模型使用全域模型ID標識，該ID是具有語法的 <provider-id>:<local-model-id> 字串，其中 <provider-id> 是提供程式的ID， <local-model-id> 是作用域為該提供程式的模型的ID。提示從儲存格的第二行開始。\n",
    "\n",
    "The `%%ai` cell magic allows you to invoke a language model of your choice with\n",
    "a given prompt. The model is identified with a **global model ID**, which is a string with the\n",
    "syntax `<provider-id>:<local-model-id>`, where `<provider-id>` is the ID of the\n",
    "provider and `<local-model-id>` is the ID of the model scoped to that provider.\n",
    "The prompt begins on the second line of the cell.\n",
    "\n",
    "例如，若要向提供程式 anthropic 和模型ID claude-v1.2 發送文字提示，請在儲存格中輸入以下代碼並執行它：\n",
    "\n",
    "For example, to send a text prompt to the provider `anthropic` and the model ID\n",
    "`claude-v1.2`, enter the following code into a cell and run it:\n",
    "\n",
    "```\n",
    "%%ai anthropic:claude-v1.2\n",
    "Write a poem about C++.\n",
    "```\n",
    "\n",
    "We currently support the following language model providers:\n",
    "\n",
    "- `ai21`\n",
    "- `anthropic`\n",
    "- `anthropic-chat`\n",
    "- `bedrock`\n",
    "- `bedrock-chat`\n",
    "- `cohere`\n",
    "- `huggingface_hub`\n",
    "- `nvidia-chat`\n",
    "- `openai`\n",
    "- `openai-chat`\n",
    "- `sagemaker-endpoint`\n",
    "\n",
    "### 列出可用型號 Listing available models\n",
    "\n",
    "Jupyter AI 還包括多個子命令，可以通過 %ai 行魔術調用這些子命令。Jupyter AI 使用子命令在筆記本中提供其他實用工具，同時保持調用語言模型的相同簡潔語法。\n",
    "\n",
    "Jupyter AI also includes multiple subcommands, which may be invoked via the\n",
    "`%ai` *line* magic. Jupyter AI uses subcommands to provide additional utilities\n",
    "in notebooks while keeping the same concise syntax for invoking a language model.\n",
    "\n",
    "該 %ai list 子命令列印可用提供程式和模型的清單。某些提供者在其 API 中顯式定義了受支援的模型清單。但是，其他供應商（如 Hugging Face Hub）缺乏明確定義的可用模型清單。在這種情況下，最好查閱供應商的上游文檔。例如，Hugging Face網站包括一個模型清單。\n",
    "\n",
    "The `%ai list` subcommand prints a list of available providers and models. Some\n",
    "providers explicitly define a list of supported models in their API. However,\n",
    "other providers, like Hugging Face Hub, lack a well-defined list of available\n",
    "models. In such cases, it's best to consult the provider's upstream\n",
    "documentation. The [Hugging Face website](https://huggingface.co/) includes a\n",
    "list of models, for example.\n",
    "\n",
    "（可選）可以將提供程式ID指定為位置參數， %ai list 以獲取一個提供程式提供的所有模型。例如， %ai list openai 將僅顯示 openai 提供程式提供的模型。\n",
    "\n",
    "Optionally, you can specify a provider ID as a positional argument to `%ai list`\n",
    "to get all models provided by one provider. For example, `%ai list openai` will\n",
    "display only models provided by the `openai` provider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abbreviated syntax 縮寫語法\n",
    "\n",
    "如果模型ID僅與一個提供程式關聯，則可以省略第一行中的 provider-id 和冒號。例如，因為是 j2-jumbo-instruct 模型的唯一提供程式，所以 ai21 可以提供完整的提供程式和模型，\n",
    "\n",
    "If your model ID is associated with only one provider, you can omit the `provider-id` and\n",
    "the colon from the first line. For example, because `ai21` is the only provider of the\n",
    "`j2-jumbo-instruct` model, you can either give the full provider and model,\n",
    "\n",
    "```\n",
    "%%ai ai21:j2-jumbo-instruct\n",
    "Write some JavaScript code that prints \"hello world\" to the console.\n",
    "```\n",
    "或者只是模型，or just the model,\n",
    "\n",
    "```\n",
    "%%ai j2-jumbo-instruct # infers AI21 provider\n",
    "Write some JavaScript code that prints \"hello world\" to the console.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設置輸出格式 Formatting the output\n",
    "\n",
    "默認情況下，Jupyter AI 假定模型將輸出 markdown，因此 %%ai 命令的輸出將預設格式化為 markdown。您可以使用 magic 命令的 -f or --format 參數覆蓋它。有效格式包括：\n",
    "\n",
    "By default, Jupyter AI assumes that a model will output markdown, so the output of\n",
    "an `%%ai` command will be formatted as markdown by default. You can override this\n",
    "using the `-f` or `--format` argument to your magic command. Valid formats include:\n",
    "\n",
    "- `code`\n",
    "- `image` (for Hugging Face Hub's text-to-image models only) （僅適用於 Hugging Face Hub 的文字轉圖像模型）\n",
    "- `markdown`\n",
    "- `math`\n",
    "- `html`\n",
    "- `json`\n",
    "- `text`\n",
    "\n",
    "例如，若要強制將命令的輸出解釋為 HTML，可以運行： For example, to force the output of a command to be interpreted as HTML, you can run:\n",
    "\n",
    "```\n",
    "%%ai anthropic:claude-v1.2 -f html\n",
    "Create a square using SVG with a black border and white fill.\n",
    "```\n",
    "\n",
    "以下儲存格將以 IPython Math 的格式生成輸出，在 Web 瀏覽器中，該格式看起來像正確排版的公式。 \n",
    "\n",
    "The following cell will produce output in IPython's `Math` format, which in a web browser\n",
    "will look like properly typeset equations.\n",
    "\n",
    "```\n",
    "%%ai chatgpt -f math\n",
    "Generate the 2D heat equation in LaTeX surrounded by `$$`. Do not include an explanation.\n",
    "```\n",
    "此提示將生成輸出作為輸入儲存格下方的代碼儲存格。 This prompt will produce output as a code cell below the input cell.\n",
    "\n",
    ":::{warning}\n",
    ":name: run-code\n",
    "**在運行或分發生成式 AI 模型之前，請查看生成式 AI 模型生成的任何代碼。回應提示時獲取的代碼可能會產生負面副作用，並且可能包括對不存在（幻覺）API 的調用。\n",
    "Please review any code that a generative AI model produces before you run it\n",
    "or distribute it.**\n",
    "The code that you get in response to a prompt may have negative side effects and may\n",
    "include calls to nonexistent (hallucinated) APIs.\n",
    ":::\n",
    "\n",
    "```\n",
    "%%ai chatgpt -f code\n",
    "A function that computes the lowest common multiples of two integers, and\n",
    "a function that runs 5 test cases of the lowest common multiple function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在提示中插值 Interpolating in prompts\n",
    "\n",
    "使用大括號語法，可以在提示符中包含變數和其他 Python 表達式。這樣，您就可以使用 IPython 內核知道但不在當前儲存格中的代碼來執行提示。\n",
    "Using curly brace syntax, you can include variables and other Python expressions in your\n",
    "prompt. This lets you execute a prompt using code that the IPython kernel knows about,\n",
    "but that is not in the current cell.\n",
    "\n",
    "例如，我們可以在一個筆記本單元格中設置一個變數： For example, we can set a variable in one notebook cell:\n",
    "\n",
    "```python\n",
    "poet = \"Walt Whitman\"\n",
    "```\n",
    "\n",
    "然後，我們可以在後面 %%ai 儲存格的命令中使用相同的變數： Then, we can use this same variable in an `%%ai` command in a later cell:\n",
    "\n",
    "```\n",
    "%%ai chatgpt\n",
    "Write a poem in the style of {poet}\n",
    "```\n",
    "\n",
    "當此單元運行時， {poet} 將插值為 Walt Whitman ，或作為當時分配給的任何 poet 內容。 When this cell runs, `{poet}` is interpolated as `Walt Whitman`, or as whatever `poet`\n",
    "is assigned to at that time.\n",
    "\n",
    "可以使用帶有 In 插值語法的特殊和 Out 清單來解釋位於 Jupyter 筆記本中其他位置的代碼。例如，如果在儲存格中運行以下代碼，並且其輸入被分配給 In[11] ：\n",
    "\n",
    "You can use the special `In` and `Out` list with interpolation syntax to explain code\n",
    "located elsewhere in a Jupyter notebook. For example, if you run the following code in\n",
    "a cell, and its input is assigned to `In[11]`:\n",
    "\n",
    "```python\n",
    "for i in range(0, 5):\n",
    "  print(i)\n",
    "```\n",
    "\n",
    "然後，您可以在 %%ai magic 命令 In[11] 中引用，它將被替換為有問題的代碼：\n",
    "\n",
    "You can then refer to `In[11]` in an `%%ai` magic command, and it will be replaced\n",
    "with the code in question:\n",
    "\n",
    "```\n",
    "%%ai cohere:command-xlarge-nightly\n",
    "Please explain the code below:\n",
    "--\n",
    "{In[11]}\n",
    "```\n",
    "您還可以使用具有相同索引的特殊 Out 清單來引用儲存格的輸出。\n",
    "You can also refer to the cell's output using the special `Out` list, with the same index.\n",
    "\n",
    "```\n",
    "%%ai cohere:command-xlarge-nightly\n",
    "Write code that would produce the following output:\n",
    "--\n",
    "{Out[11]}\n",
    "```\n",
    "\n",
    "Jupyter AI 還添加了特殊 Err 清單，該清單使用與 In 和 Out 相同的索引。例如，如果運行其中 In[3] 的代碼會產生錯誤，則會捕獲該錯誤， Err[3] 以便您可以使用提示請求解釋，例如：\n",
    "\n",
    "Jupyter AI also adds the special `Err` list, which uses the same indexes as `In` and `Out`.\n",
    "For example, if you run code in `In[3]` that produces an error, that error is captured in\n",
    "`Err[3]` so that you can request an explanation using a prompt such as:\n",
    "\n",
    "```\n",
    "%%ai chatgpt\n",
    "Explain the following Python error:\n",
    "--\n",
    "{Err[3]}\n",
    "```\n",
    "然後，您使用的 AI 模型將嘗試解釋錯誤。您還可以編寫一個同時使用兩者 In 的提示，並 Err 嘗試讓 AI 模型更正您的代碼：\n",
    "\n",
    "The AI model that you use will then attempt to explain the error. You could also write a\n",
    "prompt that uses both `In` and `Err` to attempt to get an AI model to correct your code:\n",
    "\n",
    "```\n",
    "%%ai chatgpt --format code\n",
    "The following Python code:\n",
    "--\n",
    "{In[3]}\n",
    "--\n",
    "produced the following Python error:\n",
    "--\n",
    "{Err[3]}\n",
    "--\n",
    "Write a new version of this code that does not produce that error.\n",
    "```\n",
    "作為解釋錯誤的快捷方式，您可以使用該 %ai error 命令，該命令將使用您選擇的模型解釋最新的錯誤。\n",
    "\n",
    "As a shortcut for explaining errors, you can use the `%ai error` command, which will explain the most recent error using the model of your choice.\n",
    "\n",
    "```\n",
    "%ai error anthropic:claude-v1.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 創建和管理別名 Creating and managing aliases\n",
    "\n",
    "您可以使用該 %ai register 命令為模型創建別名。例如，命令：\n",
    "\n",
    "You can create an alias for a model using the `%ai register` command. For example, the command:\n",
    "\n",
    "```\n",
    "%ai register claude anthropic:claude-v1.2\n",
    "```\n",
    "\n",
    "將別名 claude 註冊為指向 anthropic 提供程式的 claude-v1.2 模型。然後，您可以像使用任何其他型號名稱一樣使用此別名：\n",
    "\n",
    "will register the alias `claude` as pointing to the `anthropic` provider's `claude-v1.2` model. You can then use this alias as you would use any other model name:\n",
    "\n",
    "```\n",
    "%%ai claude\n",
    "Write a poem about C++.\n",
    "```\n",
    "您還可以定義自訂 LangChain 鏈：\n",
    "\n",
    "You can also define a custom LangChain chain:\n",
    "\n",
    "```python\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "```\n",
    "\n",
    "...然後用 %ai register 它給它起一個名字：\n",
    "\n",
    "… and then use `%ai register` to give it a name:\n",
    "\n",
    "```\n",
    "%ai register companyname chain\n",
    "```\n",
    "\n",
    "您可以使用以下 %ai update 命令變更別名的目標：\n",
    "\n",
    "You can change an alias's target using the `%ai update` command:\n",
    "\n",
    "```\n",
    "%ai update claude anthropic:claude-instant-v1.0\n",
    "```\n",
    "\n",
    "您可以使用以下 %ai delete 命令移除別名：\n",
    "\n",
    "You can delete an alias using the `%ai delete` command:\n",
    "\n",
    "```\n",
    "%ai delete claude\n",
    "```\n",
    "\n",
    "您可以通過執行命令 %ai list 來查看所有別名的清單。\n",
    "\n",
    "別名的名稱可以包含 ASCII 字母（大寫和小寫）、數位、連字元、下劃線和句點。它們可能不包含冒號。它們也可能不覆蓋內置命令 - 運行 %ai help 這些命令的清單。\n",
    "\n",
    "別名必須引用模型或 LLMChain 物件;它們不能引用其他別名。\n",
    "\n",
    "You can see a list of all aliases by running the `%ai list` command.\n",
    "\n",
    "Aliases' names can contain ASCII letters (uppercase and lowercase), numbers, hyphens, underscores, and periods. They may not contain colons. They may also not override built-in commands — run `%ai help` for a list of these commands.\n",
    "\n",
    "Aliases must refer to models or `LLMChain` objects; they cannot refer to other aliases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將魔術命令與 SageMaker 終端節點結合使用 Using magic commands with SageMaker endpoints\n",
    "\n",
    "您可以將魔術命令用於使用 Amazon SageMaker 託管的模型。\n",
    "\n",
    "首先，請確保在啟動 JupyterLab 之前或在 JupyterLab 中使用 %env magic 命令之前設置了 AWS_ACCESS_KEY_ID 和 AWS_SECRET_ACCESS_KEY 環境變數。有關環境變數的更多資訊，請參閱 AWS 文件中的用於配置 AWS CLI 的環境變數。\n",
    "\n",
    "Jupyter AI 支援託管在使用 JSON 架構的 SageMaker 終端節點上的語言模型。通過 boto3 開發工具包向AWS進行身份驗證，並將憑證存儲在配置檔中 default 。有關如何執行此操作的 boto3 指南，請參閱文檔。\n",
    "\n",
    "您需要在 SageMaker 中部署模型，然後將其作為模型名稱 （as sagemaker-endpoint:my-model-name ）。請參閱有關如何部署 JumpStart 模型的文件。\n",
    "\n",
    "所有 SageMaker 終端節點請求都要求您指定 --region-name 、 --request-schema 和 --response-path 選項。下面的示例假定您已經部署了一個名為 jumpstart-dft-hf-text2text-flan-t5-xl 的模型。\n",
    "\n",
    "You can use magic commands with models hosted using Amazon SageMaker.\n",
    "\n",
    "First, make sure that you've set your `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` environment variables either before starting JupyterLab or using the `%env` magic command within JupyterLab. For more information about environment variables, see [Environment variables to configure the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-envvars.html) in AWS's documentation.\n",
    "\n",
    "Jupyter AI supports language models hosted on SageMaker endpoints that use JSON schemas. Authenticate with AWS via the `boto3` SDK and have the credentials stored in the `default` profile.  Guidance on how to do this can be found in the [`boto3` documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html).\n",
    "\n",
    "You will need to deploy a model in SageMaker, then provide it as the model name (as `sagemaker-endpoint:my-model-name`). See the [documentation on how to deploy a JumpStart model](https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-deploy.html).\n",
    "\n",
    "All SageMaker endpoint requests require you to specify the `--region-name`, `--request-schema`, and `--response-path` options. The example below presumes that you have deployed a model called `jumpstart-dft-hf-text2text-flan-t5-xl`.\n",
    "\n",
    "```\n",
    "%%ai sagemaker-endpoint:jumpstart-dft-hf-text2text-flan-t5-xl --region-name=us-east-1 --request-schema={\"text_inputs\":\"<prompt>\"} --response-path=generated_texts.[0] -f code\n",
    "Write Python code to print \"Hello world\"\n",
    "```\n",
    "\n",
    "該 --region-name 參數設定為部署模型的 AWS 區域代碼，在本例中為 us-east-1 。\n",
    "\n",
    "該 --request-schema 參數是終結點期望作為輸入的 JSON 物件，提示符將替換為與字串文本匹配的任何值 \"<prompt>\" 。例如，請求架構 {\"text_inputs\":\"<prompt>\"} 將提交一個 JSON 物件，提示存儲在 text_inputs 金鑰下。\n",
    "\n",
    "該 --response-path 選項是一個 JSONPath 字串，用於從終結點的 JSON 回應中檢索語言模型的輸出。例如，如果終端節點傳回物件，其回應路徑為schema {\"generated_texts\":[\"<output>\"]} ，則其回應路徑為 generated_texts.[0] 。\n",
    "\n",
    "The `--region-name` parameter is set to the [AWS region code](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html) where the model is deployed, which in this case is `us-east-1`.\n",
    "\n",
    "The `--request-schema` parameter is the JSON object the endpoint expects as input, with the prompt being substituted into any value that matches the string literal `\"<prompt>\"`. For example, the request schema `{\"text_inputs\":\"<prompt>\"}` will submit a JSON object with the prompt stored under the `text_inputs` key.\n",
    "\n",
    "The `--response-path` option is a [JSONPath](https://goessner.net/articles/JsonPath/index.html) string that retrieves the language model's output from the endpoint's JSON response. For example, if your endpoint returns an object with the schema `{\"generated_texts\":[\"<output>\"]}`, its response path is `generated_texts.[0]`.\n",
    "\n",
    "## 配置 Configuration\n",
    "\n",
    "您可以指定允許清單，以僅允許特定的供應商清單或阻止清單來阻止某些供應商。\n",
    "\n",
    "You can specify an allowlist, to only allow only a certain list of providers, or\n",
    "a blocklist, to block some providers.\n",
    "\n",
    "### 配置預設模型和 API 金鑰 Configuring default models and API keys\n",
    "\n",
    "此配置允許設置預設語言和嵌入模型及其相應的 API 金鑰。這些值是作為使用者的起點提供的，因此他們不必選擇模型和 API 金鑰，但是，他們在設置面板中所做的選擇將優先於這些值。\n",
    "\n",
    "This configuration allows for setting a default language and embedding models, and their corresponding API keys.\n",
    "These values are offered as a starting point for users, so they don't have to select the models and API keys, however,\n",
    "the selections they make in the settings panel will take precedence over these values.\n",
    "\n",
    "指定預設語言模型 Specify default language model\n",
    "```bash\n",
    "jupyter lab --AiExtension.default_language_model=bedrock-chat:anthropic.claude-v2\n",
    "```\n",
    "\n",
    "指定預設嵌入模型 Specify default embedding model\n",
    "```bash\n",
    "jupyter lab --AiExtension.default_embeddings_model=bedrock:amazon.titan-embed-text-v1\n",
    "```\n",
    "\n",
    "指定預設 API 金鑰 Specify default API keys\n",
    "```bash\n",
    "jupyter lab --AiExtension.default_api_keys={'OPENAI_API_KEY': 'sk-abcd'}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 黑名單供應商 Blocklisting providers\n",
    "\n",
    "此配置允許在設置面板中阻止特定提供者。在下一節中，此列表優先於允許清單。\n",
    "\n",
    "This configuration allows for blocking specific providers in the settings panel.\n",
    "This list takes precedence over the allowlist in the next section.\n",
    "\n",
    "```\n",
    "jupyter lab --AiExtension.blocked_providers=openai\n",
    "```\n",
    "\n",
    "若要阻止清單中的多個提供程式，請重複運行時配置。\n",
    "\n",
    "To block more than one provider in the block-list, repeat the runtime\n",
    "configuration.\n",
    "\n",
    "```\n",
    "jupyter lab --AiExtension.blocked_providers=openai --AiExtension.blocked_providers=ai21\n",
    "```\n",
    "\n",
    "### 將供應商列入允許名單 Allowlisting providers\n",
    "\n",
    "這個配置允許將設置面板中的提供程式清單篩選為僅一組列入允許清單的提供者。This configuration allows for filtering the list of providers in the settings\n",
    "panel to only an allowlisted set of providers.\n",
    "\n",
    "```\n",
    "jupyter lab --AiExtension.allowed_providers=openai\n",
    "```\n",
    "\n",
    "若要允許允許清單中有多個提供程式，請重複運行時配置。To allow more than one provider in the allowlist, repeat the runtime\n",
    "configuration.\n",
    "\n",
    "```\n",
    "jupyter lab --AiExtension.allowed_providers=openai --AiExtension.allowed_providers=ai21\n",
    "```\n",
    "\n",
    "### 模型參數 Model parameters\n",
    "\n",
    "此配置允許指定解壓縮並傳遞給提供程式類的任意參數。這對於傳遞影響模型生成響應的參數（如模型調整）非常有用。這也是傳入某些提供程式/模型所需的自定義屬性的合適位置。This configuration allows specifying arbitrary parameters that are unpacked and\n",
    "passed to the provider class. This is useful for passing parameters such as\n",
    "model tuning that affect the response generation by the model. This is also an\n",
    "appropriate place to pass in custom attributes required by certain\n",
    "providers/models.\n",
    "\n",
    "接受的值是一個字典，其中頂級鍵作為模型 ID （provider：model_id），value 應該是任何解壓縮並按原樣傳遞給提供程式類的任意字典。The accepted value is a dictionary, with top level keys as the model id\n",
    "(provider:model_id), and value should be any arbitrary dictionary which is\n",
    "unpacked and passed as-is to the provider class.\n",
    "\n",
    "#### 配置為啟動選項 Configuring as a startup option\n",
    "\n",
    "在此範例中，將使用選擇模型 model_kwargs 時 ai21.j2-mid-v1 的值創建 bedrock 提供程式。In this sample, the `bedrock` provider will be created with the value for\n",
    "`model_kwargs` when `ai21.j2-mid-v1` model is selected.\n",
    "\n",
    "```bash\n",
    "jupyter lab --AiExtension.model_parameters bedrock:ai21.j2-mid-v1='{\"model_kwargs\":{\"maxTokens\":200}}'\n",
    "```\n",
    "\n",
    "請注意，使用字典周圍的單引號來轉義雙引號。這在某些shell中是必需的。以上將導致生成以下LLM類。Note the usage of single quotes surrounding the dictionary to escape the double\n",
    "quotes. This is required in some shells. The above will result in the following\n",
    "LLM class to be generated.\n",
    "\n",
    "```python\n",
    "BedrockProvider(model_kwargs={\"maxTokens\":200}, ...)\n",
    "```\n",
    "\n",
    "下面是另一個示例，其中 anthropic 將使用 max_tokens 和 temperature 的值創建提供程式，選擇 claude-2 model時。Here is another example, where `anthropic` provider will be created with the\n",
    "values for `max_tokens` and `temperature`, when `claude-2` model is selected.\n",
    "\n",
    "\n",
    "```bash\n",
    "jupyter lab --AiExtension.model_parameters anthropic:claude-2='{\"max_tokens\":1024,\"temperature\":0.9}'\n",
    "```\n",
    "\n",
    "以上將導致生成以下LLM類。The above will result in the following LLM class to be generated.\n",
    "\n",
    "```python\n",
    "AnthropicProvider(max_tokens=1024, temperature=0.9, ...)\n",
    "```\n",
    "\n",
    "要在命令行中傳遞多個模型的多組模型參數，可以將它們作為附加參數附加到 --AiExtension.model_parameters ，如下所示。To pass multiple sets of model parameters for multiple models in the\n",
    "command-line, you can append them as additional arguments to\n",
    "`--AiExtension.model_parameters`, as shown below.\n",
    "\n",
    "```bash\n",
    "jupyter lab \\\n",
    "--AiExtension.model_parameters bedrock:ai21.j2-mid-v1='{\"model_kwargs\":{\"maxTokens\":200}}' \\\n",
    "--AiExtension.model_parameters anthropic:claude-2='{\"max_tokens\":1024,\"temperature\":0.9}'\n",
    "```\n",
    "\n",
    "但是，對於更複雜的配置，我們強烈建議您在專用配置檔中指定此配置。我們將在下一節中介紹如何做到這一點。However, for more complex configuration, we highly recommend that you specify\n",
    "this in a dedicated configuration file. We will describe how to do so in the\n",
    "following section.\n",
    "\n",
    "#### 配置為配置檔 Configuring as a config file\n",
    "\n",
    "此配置也可以在 json 格式的配置檔中指定。This configuration can also be specified in a config file in json format.\n",
    "\n",
    "下面是為 ai21.j2-mid-v1 模型配置 bedrock 提供程式的範例。Here is an example for configuring the `bedrock` provider for `ai21.j2-mid-v1`\n",
    "model.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"AiExtension\": {\n",
    "        \"model_parameters\": {\n",
    "            \"bedrock:ai21.j2-mid-v1\": {\n",
    "                \"model_kwargs\": {\n",
    "                    \"maxTokens\": 200\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "有幾種方法可以指定 JupyterLab 來選擇此配置。There are several ways to specify JupyterLab to pick this config.\n",
    "\n",
    "第一個選項是將此設定保存在檔中，並在啟動時使用 --config or -c 選項指定檔案路徑。The first option is to save this config in a file and specifying the filepath at startup using the `--config` or `-c` option.\n",
    "\n",
    "```bash\n",
    "jupyter lab --config <config-file-path>\n",
    "```\n",
    "\n",
    "第二種選擇是將其放在 JupyterLab 掃描配置檔的位置。在這種情況下，應命名 jupyter_jupyter_ai_config.json 該檔。您可以通過運行 jupyter --paths 命令並從 config 該部分中選擇其中一條路徑來查找這些路徑。The second option is to drop it in a location that JupyterLab scans for configuration files.\n",
    "The file should be named `jupyter_jupyter_ai_config.json` in this case. You can find these paths by running `jupyter --paths`\n",
    "command, and picking one of the paths from the `config` section.\n",
    "\n",
    "下面是運行該 jupyter --paths 命令的範例。Here is an example of running the `jupyter --paths` command.\n",
    "\n",
    "```bash\n",
    "(jupyter-ai-lab4) ➜ jupyter --paths\n",
    "config:\n",
    "    /opt/anaconda3/envs/jupyter-ai-lab4/etc/jupyter\n",
    "    /Users/3coins/.jupyter\n",
    "    /Users/3coins/.local/etc/jupyter\n",
    "    /usr/3coins/etc/jupyter\n",
    "    /etc/jupyter\n",
    "data:\n",
    "    /opt/anaconda3/envs/jupyter-ai-lab4/share/jupyter\n",
    "    /Users/3coins/Library/Jupyter\n",
    "    /Users/3coins/.local/share/jupyter\n",
    "    /usr/local/share/jupyter\n",
    "    /usr/share/jupyter\n",
    "runtime:\n",
    "    /Users/3coins/Library/Jupyter/runtime\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
